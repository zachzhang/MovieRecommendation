{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "print(sys.version)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MF_RS():\n",
    "    def __init__(self, numUsers, numSongs, embedding_dim, reg_lambda = 0.01):\n",
    "        \n",
    "        #hyper parameters\n",
    "        self.batch_size = np.min([256, numUsers, numSongs]);\n",
    "        self.numUsers = numUsers\n",
    "        self.numSongs = numSongs\n",
    "        self.epochs = 50\n",
    "        self.reg_lambda = reg_lambda\n",
    "        \n",
    "        #embedding matricies for users and songs\n",
    "        self.userMat = tf.Variable(tf.random_normal([numUsers, embedding_dim]))\n",
    "        self.songMat = tf.Variable(tf.random_normal([numSongs, embedding_dim]))\n",
    "        self.userBias = tf.Variable(tf.random_normal([numUsers]))\n",
    "        self.songBias = tf.Variable(tf.random_normal([numSongs]))\n",
    "        self.overallBias = tf.Variable(tf.random_normal([1]))\n",
    "        \n",
    "        #input tensors for songs, usres, ratings\n",
    "        self.users = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.songs = tf.placeholder(tf.int32, shape =(self.batch_size))\n",
    "        self.rating = tf.placeholder(tf.float32, shape = (self.batch_size))\n",
    "        \n",
    "        #map each user/song to its feature vector\n",
    "        self.U = tf.nn.embedding_lookup(self.userMat, self.users)\n",
    "        self.W = tf.nn.embedding_lookup(self.songMat, self.songs)\n",
    "        #map each user/song bias to its bias vector\n",
    "        self.U_bias = tf.nn.embedding_lookup(self.userBias, self.users)\n",
    "        self.W_bias = tf.nn.embedding_lookup(self.songBias, self.songs)\n",
    "        \n",
    "        #predicted rating is dot product of user and song\n",
    "        bias = self.U_bias+self.W_bias+self.overallBias\n",
    "        pq = tf.reduce_sum(tf.mul(self.U, self.W), 1)\n",
    "        self.yhat = pq + bias\n",
    "        \n",
    "        self.reg = self.reg_lambda * ( tf.reduce_sum((tf.square(self.U) + tf.square(self.W))) + \n",
    "                                 tf.reduce_sum(tf.square(self.U_bias) + tf.square(self.W_bias)))\n",
    "        self.error = tf.reduce_mean(tf.nn.l2_loss(self.yhat - self.rating))\n",
    "        self.cost = (self.error + self.reg)/1e4\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = .01).minimize(self.cost)\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())   \n",
    "        \n",
    "        \n",
    "    def train(self, users, songs, ratings, verb = 0):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            avg_cost = 0\n",
    "            perm = np.random.permutation(len(ratings))\n",
    "            num_batches = len(ratings) // self.batch_size\n",
    "            \n",
    "            for b_idx in range(num_batches):\n",
    "                \n",
    "                batch = perm[self.batch_size * b_idx:self.batch_size * (b_idx + 1)]\n",
    "                users_batch = users[batch]\n",
    "                songs_batch = songs[batch]\n",
    "                ratings_batch = ratings[batch]\n",
    "                                \n",
    "                avg_cost += self.session.run([self.cost, self.optimizer],\n",
    "                          {self.users:users_batch, self.songs:songs_batch, self.rating:ratings_batch})[0]\n",
    "            if verb > 0:\n",
    "                print(avg_cost/num_batches)\n",
    "    def test(self, users, songs):\n",
    "        yhat = np.zeros(len(users))\n",
    "        num_batches = len(users) // self.batch_size\n",
    "        for b_idx in range(num_batches):\n",
    "            batch = range(self.batch_size * b_idx,self.batch_size * (b_idx + 1))\n",
    "            users_batch = users[batch]\n",
    "            songs_batch = songs[batch]\n",
    "            yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        batch = range(-self.batch_size,0)\n",
    "        users_batch = users[batch]\n",
    "        songs_batch = songs[batch]\n",
    "        yhat[batch] = self.session.run([self.yhat],\n",
    "                      {self.users:users_batch, self.songs:songs_batch})[0]\n",
    "        return yhat\n",
    "    def evaluate(self, users, songs, ratings):\n",
    "        yhat = self.test(users, songs)\n",
    "        return np.mean((yhat - ratings)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([4, 3, 2, 5, 1])\n",
    "#unique users / songs\n",
    "uni_a = np.unique(a)\n",
    "uni_b = np.unique(b)\n",
    "\n",
    "#dict mapping the id to an index\n",
    "a_map = dict(zip(uni_a,range(len(uni_a))))\n",
    "b_map = dict(zip(uni_b,range(len(uni_b))))\n",
    "\n",
    "user_idx =  np.array([ a_map[user] for user in a])\n",
    "song_idx =  np.array([ b_map[song] for song in b])\n",
    "model = MF_RS(len(uni_a), len(uni_b), 7)\n",
    "np.random.seed(2)\n",
    "model.train(user_idx, song_idx, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#movieratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe(include = 'all').T\n",
    "    var = pd.DataFrame(data = {'nanvals': pd.Series(), 'number_distinct': pd.Series()})\n",
    "    for i in range(len(input_data.columns)):\n",
    "        nanvals = input_data.ix[:,i].isnull().sum()\n",
    "        number_distinct = len(input_data.ix[:,i].value_counts())\n",
    "        var = var.append(pd.DataFrame([[nanvals, number_distinct]], columns = ['nanvals', 'number_distinct']))\n",
    "    var.index = output_data.index.values\n",
    "    output_data['nanvals'] = var['nanvals']\n",
    "    output_data['number_distinct'] = var['number_distinct']\n",
    "    return output_data\n",
    "output_data = getDfSummary(movieratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 9066\n"
     ]
    }
   ],
   "source": [
    "users = movieratings.ix[:,0].values\n",
    "songs = movieratings.ix[:,1].values\n",
    "ratings = movieratings.ix[:,2].values\n",
    "\n",
    "#unique users / songs\n",
    "uni_users = movieratings['userId'].unique()\n",
    "uni_songs = movieratings['movieId'].unique()\n",
    "\n",
    "#dict mapping the id to an index\n",
    "user_map = dict(zip(uni_users,range(len(uni_users))))\n",
    "song_map = dict(zip(uni_songs,range(len(uni_songs))))\n",
    "\n",
    "user_idx =  np.array([ user_map[user] for user in users])\n",
    "song_idx =  np.array([ song_map[song] for song in songs])\n",
    "\n",
    "print(len(uni_users),len(uni_songs))\n",
    "\n",
    "perm = np.random.permutation(len(users))\n",
    "trn_idx = perm[:(len(users)*2)//3]\n",
    "val_idx = perm[(len(users)*2)//3:]\n",
    "user_idx_trn, song_idx_trn, ratings_trn = user_idx[trn_idx], song_idx[trn_idx], ratings[trn_idx]\n",
    "user_idx_val, song_idx_val, ratings_val = user_idx[val_idx], song_idx[val_idx], ratings[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.7537167349\n",
      "0.135181915388\n",
      "0.0437637791611\n",
      "0.0242391984265\n",
      "0.0169461095598\n",
      "0.0134796154327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5747530805150691"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songmodel = MF_RS(len (uni_users), len(uni_songs), 11)\n",
    "print(songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "songmodel.epochs = 5\n",
    "songmodel.train(user_idx_trn, song_idx_trn, ratings_trn, verb = 1)\n",
    "songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before training 32.1155875485\n",
      "MSE after training with edim:  10  and lambda:  0.0001 :  1.683918244\n",
      "accuracy before training 34.1550168502\n",
      "MSE after training with edim:  10  and lambda:  0.001 :  1.54896450299\n",
      "accuracy before training 29.0724622023\n",
      "MSE after training with edim:  10  and lambda:  0.01 :  1.2319141748\n",
      "accuracy before training 38.358601842\n",
      "MSE after training with edim:  30  and lambda:  0.0001 :  1.74010306599\n",
      "accuracy before training 35.7440668672\n",
      "MSE after training with edim:  30  and lambda:  0.001 :  1.62174960509\n",
      "accuracy before training 39.5166206504\n",
      "MSE after training with edim:  30  and lambda:  0.01 :  1.14792215951\n",
      "accuracy before training 72.2251364808\n",
      "MSE after training with edim:  50  and lambda:  0.0001 :  1.66884400978\n",
      "accuracy before training 63.7559466565\n",
      "MSE after training with edim:  50  and lambda:  0.001 :  1.52872108995\n",
      "accuracy before training 66.8933485054\n",
      "MSE after training with edim:  50  and lambda:  0.01 :  1.10677696057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.68391824,  1.5489645 ,  1.23191417],\n",
       "       [ 1.74010307,  1.62174961,  1.14792216],\n",
       "       [ 1.66884401,  1.52872109,  1.10677696]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edims = [10, 30, 50]\n",
    "lambdas = [10**i for i in range(-4, -1)]\n",
    "errmat = np.zeros([len(edims), len(lambdas)])\n",
    "for eidx, edim in enumerate(edims):\n",
    "    for lidx, lamb in enumerate(lambdas):\n",
    "        songmodel = MF_RS(len (uni_users), len(uni_songs), edim, reg_lambda=lamb)\n",
    "        print(\"accuracy before training\", songmodel.evaluate(user_idx_val, song_idx_val, ratings_val))\n",
    "        np.random.seed(1)\n",
    "        songmodel.train(user_idx_trn, song_idx_trn, ratings_trn)\n",
    "        err = songmodel.evaluate(user_idx_val, song_idx_val, ratings_val)\n",
    "        print(\"MSE after training with edim: \", edim, \" and lambda: \", lamb, \": \", err)\n",
    "        errmat[eidx, lidx] = err\n",
    "errmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
